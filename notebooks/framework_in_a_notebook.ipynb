{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the \"framework\" branch from GitHub and use the \"hermes\" folder as a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Install necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pip\n",
    "\n",
    "def _install(package):\n",
    "    pip.main(['install', package])\n",
    "\n",
    "def _import(package):\n",
    "    importlib.import_module(package)\n",
    "    \n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        _import(package)\n",
    "    except ImportError:\n",
    "        _install(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GitPython\n",
      "  Downloading GitPython-1.0.1.tar.gz (355kB)\n",
      "Collecting gitdb>=0.6.4 (from GitPython)\n",
      "  Downloading gitdb-0.6.4.tar.gz (400kB)\n",
      "Collecting smmap>=0.8.5 (from gitdb>=0.6.4->GitPython)\n",
      "  Downloading smmap-0.9.0.tar.gz\n",
      "Building wheels for collected packages: GitPython, gitdb, smmap\n",
      "  Running setup.py bdist_wheel for GitPython\n",
      "  Stored in directory: /Users/tiffanyj/Library/Caches/pip/wheels/23/f4/31/1d0570ae6ecccca26eafb087788483f614cd740281fd842660\n",
      "  Running setup.py bdist_wheel for gitdb\n",
      "  Stored in directory: /Users/tiffanyj/Library/Caches/pip/wheels/63/1b/54/87cf226ccefad0e5fdc78e3c8c65180ac77ed2a04d1dec3a56\n",
      "  Running setup.py bdist_wheel for smmap\n",
      "  Stored in directory: /Users/tiffanyj/Library/Caches/pip/wheels/47/75/63/333cdcb6d3e6e8eb1ec6869564b84f7f1e6a875d87541a0ae9\n",
      "Successfully built GitPython gitdb smmap\n",
      "Installing collected packages: smmap, gitdb, GitPython\n",
      "Successfully installed GitPython-1.0.1 gitdb-0.6.4 smmap-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 7.1.2, however version 8.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting click\n",
      "  Downloading click-6.2-py2.py3-none-any.whl (70kB)\n",
      "Installing collected packages: click\n",
      "Successfully installed click-6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 7.1.2, however version 8.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "install_and_import(\"GitPython\")\n",
    "install_and_import(\"click\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create a temporary directory.\n",
    "\n",
    "Step 3: Git clone the \"framework\" branch from GitHub to the temporary directory.\n",
    "\n",
    "Step 4: Zip the hermes source files.\n",
    "\n",
    "Step 5: Add zip to SparkContext.\n",
    "\n",
    "Step 6: Remove temporary directory once it is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remote_url = \"https://github.com/tiffanyj41/hermes.git\"\n",
    "remote_branch = \"framework\"\n",
    "source_dir = \"hermes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import os\n",
    "import functools\n",
    "\n",
    "def _list_all_in_dir(dir_path):\n",
    "    for path, subdirs, files in os.walk(dir_path):\n",
    "        for filename in files:\n",
    "            print os.path.join(path, filename)\n",
    "            \n",
    "def _zip_dir(srcdir_path, zipfile_handler):\n",
    "    try:\n",
    "        zipfile_handler.writepy(srcdir_path)\n",
    "    finally:\n",
    "        zipfile_handler.close()\n",
    "            \n",
    "def trackcalls(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.has_been_called = True\n",
    "        return func(*args, **kwargs)\n",
    "    wrapper.has_been_called = False\n",
    "    return wrapper\n",
    "\n",
    "@trackcalls\n",
    "def _add_zipfile_to_sc(zipfile_path):\n",
    "    sc.addPyFile(zipfile_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4a579f0520de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# create a temporary directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "import git\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import zipfile    \n",
    "\n",
    "# create a temporary directory\n",
    "tmpdir_path = tempfile.mkdtemp()\n",
    "if debug: print \"temporary directory: %s\\n\" % tmpdir_path\n",
    "\n",
    "# ensure file is read/write by creator only\n",
    "saved_umask = os.umask(0077)\n",
    "\n",
    "# create a zipfile handler to zip the necessary files\n",
    "ziptmpdir_path = tempfile.mkdtemp()\n",
    "if debug: print \"temporary directory for zip file: %s\\n\" % ziptmpdir_path\n",
    "zipfile_path = ziptmpdir_path + \"/hermes_src.zip\"\n",
    "if debug: print \"zip file's path: %s\\n\" % zipfile_path\n",
    "zipfile_handler = zipfile.PyZipFile(zipfile_path, \"w\")\n",
    "\n",
    "# make zipfile handler verbose for debugging\n",
    "zipfile_handler.debug = 3\n",
    "\n",
    "try:\n",
    "    # clone \"framework\" branch from GitHub into temporary directory\n",
    "    local_branch = git.Repo.clone_from(remote_url, tmpdir_path, branch=remote_branch)\n",
    "    if debug: print \"current branch: %s\\n\" % local_branch.head.ref\n",
    "    if debug: print \"list all in %s:\" % tmpdir_path; _list_all_in_dir(tmpdir_path); print \"\\n\"\n",
    "        \n",
    "    # zip \"hermes\" directory\n",
    "    if debug: print \"zipping: %s\\n\" % os.path.join(tmpdir_path, source_dir)\n",
    "    _zip_dir(os.path.join(tmpdir_path, source_dir), zipfile_handler)\n",
    "    \n",
    "    # check zip file\n",
    "    if debug: print \"Is zip file %s valid? %s\\n\" % (zipfile_path, zipfile.is_zipfile(zipfile_path))\n",
    "    \n",
    "    # add zip to SparkContext \n",
    "    # note: you can only add zip to SparkContext one time\n",
    "    if not _add_zipfile_to_sc.has_been_called:\n",
    "        if debug: print \"add zip file %s into spark context\\n\" % zipfile_path\n",
    "        _add_zipfile_to_sc(zipfile_path)\n",
    "    else:\n",
    "        if debug: print \"zip file %s is already added into spark context; will not re-add\\n\" % zipfile_path\n",
    "    \n",
    "except IOError as e:\n",
    "    raise e\n",
    "else:\n",
    "    os.remove(zipfile_path)\n",
    "finally:\n",
    "    os.umask(saved_umask)\n",
    "    shutil.rmtree(tmpdir_path)\n",
    "    shutil.rmtree(ziptmpdir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "* Run movielens_10m_ratings with **ratings** vector transformation\n",
    "* Implement **ALS** recommender system algorithms\n",
    "* Implement **RMSE, MAE** metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framework is based on a state machine. Since you are using a notebook, it is unlikely that you will use a state machine to automate the process, but you can use parts of the state machine to do what you need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: __start()\n",
    "**For those who use [MovieLens 1M CF test src code](http://l41-srv-mcdh32.b.internal:8880/notebooks/Hermes/MovieLens%201M%20CF%20test%20src%20code.ipynb#) as guidance, this is executing the pre-requisites when the HDFS directory and the input data are not defined yet.**\n",
    "\n",
    "Function: \n",
    "* __start() creates the HDFS directory and uploads the input data. \n",
    "* __start() implements the start_state of the state machine.\n",
    "\n",
    "```bash\n",
    "\n",
    "def __start(cargo):\n",
    "    \"\"\"start_state without the state machine.\"\"\"\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"In start_state:\")\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"Creating the hdfs directory \" + cargo.hdfs_dir)\n",
    "    os.system(\"hdfs dfs -mkdir \" + cargo.hdfs_dir)\n",
    "\n",
    "    def load_json_files(datas):\n",
    "        for i in range(0, len(datas)):\n",
    "            json_path = datas[i].datapath\n",
    "            if Globals.verbose: Globals.logger.debug(\"Loading JSON file \" + json_path + \" into hdfs directory \" + cargo.hdfs_dir)\n",
    "            os.system(\"hdfs dfs -put \" + json_path + \" \" + cargo.hdfs_dir + \"/\" + os.path.basename(json_path))\n",
    "\n",
    "    load_json_files(cargo.datas)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tiffanyj/datasets/movielens/movielens_1m_movies.json.gz\n",
      "/datasets/movielens/1m/movielens_1m_movies.json.gz\n",
      "/home/tiffanyj/datasets/movielens/movielens_1m_ratings.json.gz\n",
      "/datasets/movielens/1m/movielens_1m_ratings.json.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "hdfs_dir = \"/datasets/movielens/1m\"\n",
    "movies_json_path = \"/home/tiffanyj/datasets/movielens/movielens_1m_movies.json.gz\"\n",
    "movies_json_path_in_hdfs = hdfs_dir + \"/\" + os.path.basename(movies_json_path)\n",
    "ratings_json_path = \"/home/tiffanyj/datasets/movielens/movielens_1m_ratings.json.gz\"\n",
    "ratings_json_path_in_hdfs = hdfs_dir + \"/\" + os.path.basename(ratings_json_path)\n",
    "\n",
    "print movies_json_path\n",
    "print movies_json_path_in_hdfs\n",
    "print ratings_json_path \n",
    "print ratings_json_path_in_hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: You implement what is already in __start() manually yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# create hdfs_dir \n",
    "os.system(\"hdfs dfs -mkdir \" + hdfs_dir)\n",
    "# put json located at json_path into hdfs_dir\n",
    "os.system(\"hdfs dfs -put \" + ratings_json_path + \" \" + ratings_json_path_in_hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named hermes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9f5653d26eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhermes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# define Data (ie. UserVectorData) which is a class wrapper of the json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# and will be used to create a Vector (ie. UserVector)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named hermes"
     ]
    }
   ],
   "source": [
    "from hermes import *\n",
    "import modules.data\n",
    "\n",
    "# define Data (ie. UserVectorData) which is a class wrapper of the json \n",
    "# and will be used to create a Vector (ie. UserVector)\n",
    "datapath = ratings_json_path\n",
    "vector_transformation = \"ratings\"\n",
    "schemapath = None\n",
    "dataname = \"movielens\"\n",
    "\n",
    "uservectordata = modules.data.UserVectorData(datapath, vector_transformation, schemapath, dataname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: You execute using the __start() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import hermes where __start() function is defined\n",
    "from hermes import *\n",
    "# import cargo where Cargo class is defined\n",
    "import modules.cargo\n",
    "# import data where configuration is defined\n",
    "import modules.data\n",
    "\n",
    "# create cargo\n",
    "cargo = modules.cargo.Cargo()\n",
    "\n",
    "# add items to cargo\n",
    "cargo.hdfs_dir = hdfs_dir\n",
    "\n",
    "# define Data and put it in cargo\n",
    "dataname = \"movielens\"\n",
    "datapath = ratings_json_path\n",
    "vector_transformation = \"ratings\"\n",
    "schemapath = None\n",
    "uservectordata = modules.data.UserVectorData(datapath, vector_transformation, schemapath, dataname)\n",
    "cargo.datas.append(uservectordata)\n",
    "\n",
    "# call the start function\n",
    "hermes.__start(cargo)\n",
    "\n",
    "uservectordata = cargo.datas[0]\n",
    "uservectordata.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: __json_to_rdd()\n",
    "**For those who use [MovieLens 1M CF test src code](http://l41-srv-mcdh32.b.internal:8880/notebooks/Hermes/MovieLens%201M%20CF%20test%20src%20code.ipynb#) as guidance, this is accomplishing cell # 5, 6, 7.**\n",
    "\n",
    "Function: \n",
    "* __json_to_rdd() parses JSON to RDD. \n",
    "* __json_to_rdd() implements the json_to_rdd state of the state machine.\n",
    "\n",
    "```bash\n",
    "    \"\"\"json_to_rdd_state without the state macine.\"\"\"\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"In json_to_rdd_state:\")\n",
    "\n",
    "    # create RDD for each JSON file and store it in Cargo's vectors list\n",
    "    for i in range(0, len(cargo.datas)):\n",
    "        data = cargo.datas[i]\n",
    "        if Globals.verbose: Globals.logger.debug(\"Working with json file %s\" % data.datapath)\n",
    "\n",
    "        if Globals.verbose: Globals.logger.debug(\"Creating dataframe based on the content of the json file\")\n",
    "        datapath_in_hdfs = \"hdfs://\" + cargo.fs_default_ip_addr + \"/\" + cargo.hdfs_dir + \"/\" + os.path.basename(data.datapath)\n",
    "        data.set_dataframe(Globals.scsingleton.sc, Globals.scsingleton.sqlCtx, datapath_in_hdfs)\n",
    "\n",
    "        if Globals.verbose: Globals.logger.debug(\"Creating RDD based on the computed dataframe and configuration provided by the user\")\n",
    "        cargo.vectors.append( vg.VectorFactory().create_obj_vector(data, cargo.support_files) ) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: You implement what is already in __json_to_rdd() manually yourself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import modules.data\n",
    "import modules.vectorgenerator\n",
    "\n",
    "# convert JSON to Dataframe\n",
    "uservectordata.set_dataframe(sc, sqlCtx, ratings_json_path_in_hdfs) \n",
    "ratings = uservectordata.dataframe # extracting dataframe variable from UserVectorData class\n",
    "\n",
    "# this is the same thing as \n",
    "# ratings = sqlCtx.read.json(\"hdfs://\" + ratings_json_path_in_hdfs)\n",
    "# ratings.repartition(sc.defaultParallelism * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import modules.vectorgenerator\n",
    "import modules.vg\n",
    "\n",
    "# support_files is a dictionary that you can pass in during vector creation \n",
    "support_files = {}\n",
    "\n",
    "# convert DataFrame to RDD\n",
    "mv = modules.vectorgenerator.VectorFactory().create_obj_vector(uservectordata, None, True) \n",
    "all_user_ratings = mv.vector\n",
    "\n",
    "# this is the same thing as \n",
    "# mv = movieLens_vectorize.movieLens_vectorize(ratings, None, \"ratings\", \"none\")\n",
    "# all_user_ratings = mv.get_user_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(all_user_ratings)\n",
    "all_user_ratings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: You execute using the __json_to_rdd() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "\n",
    "cargo.fs_default_ip_addr = \"\"\n",
    "cargo.hdfs_dir = hdfs_dir[1:]\n",
    "cargo.support_files = {}\n",
    "\n",
    "# call json_to_rdd function\n",
    "hermes.__json_to_rdd(cargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = cargo.vectors[0]\n",
    "all_user_ratings = mv.vector\n",
    "print type(all_user_ratings)\n",
    "all_user_ratings.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: __split_data()\n",
    "**For those who use [MovieLens 1M CF test src code](http://l41-srv-mcdh32.b.internal:8880/notebooks/Hermes/MovieLens%201M%20CF%20test%20src%20code.ipynb#) as guidance, this is accomplishing cell # 8, 9.**\n",
    "\n",
    "Function: \n",
    "* __split_data() splits data to train, test, and (optional) validate. \n",
    "* __split_data() implements the split_data_state of the state machine.\n",
    "\n",
    "```bash\n",
    "def __split_data(cargo):\n",
    "    \"\"\"split_data_state without the state machine.\"\"\"\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"In split_data_state:\")\n",
    "\n",
    "    for i in range(0, len(cargo.vectors)):\n",
    "        vector = cargo.vectors[i]\n",
    "        weights, seed = hermesui._ask_user_for_split_percentage(vector.data.datapath)\n",
    "        vector.split_data(weights, seed)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingPercentage = 60/100.\n",
    "testPercentage = 40/100.\n",
    "validationPercentage = 0/100.\n",
    "seed = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: You implement what is already in __split_data() manually yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uservector = mv\n",
    "\n",
    "uservector.split_data([trainingPercentage, testPercentage, validationPercentage], seed)\n",
    "train_ratings = uservector.training_vector\n",
    "test_ratings = uservector.test_vector\n",
    "validation_ratings = uservector.validation_vector\n",
    "\n",
    "# this is the same thing as\n",
    "# train_ratings, test_ratings = uservector.vector.randomSplit([0.6, 0.4], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ratings.cache()\n",
    "test_ratings.cache()\n",
    "validation_ratings.cache()\n",
    "\n",
    "print train_ratings.count(), test_ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: you execute using the __split_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# TODO: will implement later\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hermes import *\n",
    "\n",
    "# call split_data function\n",
    "hermes.__split_data(cargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = cargo.vectors[0]\n",
    "train_ratings = mv.training_vector\n",
    "test_ratings = mv.test_vector\n",
    "validation_ratings = mv.validation_vector\n",
    "print train_ratings.count(), test_ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: __make_prediction()\n",
    "**For those who use [MovieLens 1M CF test src code](http://l41-srv-mcdh32.b.internal:8880/notebooks/Hermes/MovieLens%201M%20CF%20test%20src%20code.ipynb#) as guidance, this is accomplishing cell # 10.**\n",
    "\n",
    "Function: \n",
    "* __make_prediction() develop model based on the train data and make prediction based on this model. \n",
    "* __make_prediction() implements the make_prediction_state of the state machine.\n",
    "\n",
    "```bash\n",
    "def __make_prediction(cargo):\n",
    "    \"\"\"make_prediction_state without the state machine.\"\"\"\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"In make_prediction_state:\")   \n",
    "\n",
    "    for i in range(0, len(cargo.vectors)):\n",
    "        thisvector = cargo.vectors[i]\n",
    "\n",
    "        # select which recommenders based on the vector type\n",
    "        recommenders = None\n",
    "        thisvector_uservector = None\n",
    "        thisvector_contentvector = None\n",
    "        if helper.is_direct_subclass(thisvector, vg.UserVector):\n",
    "            if Globals.verbose: Globals.logger.debug(\"Iterating through recommenders for user vector on data %s\", thisvector.data.datapath)\n",
    "            thisvector_uservector = thisvector\n",
    "            recommenders = cargo.user_recommenders\n",
    "        elif helper.is_direct_subclass(thisvector, vg.ContentVector):\n",
    "            if Globals.verbose: Globals.logger.debug(\"Iterating through recommenders for content vector on data %s\", thisvector.data.datapath)\n",
    "            thisvector_contentvector = thisvector\n",
    "            thisvector_uservector = thisvector.uservector\n",
    "            recommenders = cargo.content_recommenders\n",
    "\n",
    "        # run all recommenders on the vector\n",
    "        for r in recommenders:\n",
    "            if Globals.verbose: Globals.logger.debug(\"Making recommendation %s on data %s\", r, thisvector.data.datapath)\n",
    "            # TODO: implement other use case, ie. WithTfidf(), etc.\n",
    "            recommender = rg.RecommenderFactory().create_obj_recommender(r, thisvector_uservector, thisvector_contentvector)\n",
    "            # default use case\n",
    "            # recommender = RecommenderFactory().create_obj_recommender(r, vector, Default())\n",
    "            # with tf-idf use case \n",
    "            # recommender = RecommenderFactory().create_obj_recommender(r, vector, WithTfidf())\n",
    "            # without tf-idf use case\n",
    "            # recommender = RecommenderFactory().create_obj_recommender(r, vector, WithoutTfidf())\n",
    "            # etc.\n",
    "            with Timer() as t:\n",
    "                prediction_vector = recommender.make_prediction()\n",
    "            if Globals.verbose: Globals.logger.debug(\"Making prediction takes %s seconds\" % t.secs)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: You implement what is already in __make_prediciton() manually yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import modules.recommendergenerator\n",
    "\n",
    "# create recommender object with the default use case\n",
    "recommender_str = \"ALS\"\n",
    "recommender = modules.recommendergenerator.RecommenderFactory().create_obj_recommender(recommender_str, uservector)\n",
    "# or\n",
    "# modules.recommendergenerator.RecommenderFactory().create_obj_recommender(recommender, uservector, Default())\n",
    "\n",
    "# get the prediction vector\n",
    "prediction_vector = recommender.make_prediction()\n",
    "# or\n",
    "# prediction_vector = uservector.prediction\n",
    "predicted1 = prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=36455, product=12, rating=3.1620100630939234),\n",
       " Rating(user=13019, product=12, rating=3.009068937170033),\n",
       " Rating(user=1199, product=12, rating=1.889880680902047),\n",
       " Rating(user=56039, product=12, rating=1.8340114917394583),\n",
       " Rating(user=68279, product=12, rating=2.575869762437719)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_vector.cache()\n",
    "predicted1.cache()\n",
    "\n",
    "print type(predicted1)\n",
    "predicted1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import algorithms.cf\n",
    "\n",
    "# instead of doing the step above, you can also call the function directly\n",
    "prediction_vector = algorithms.cf.calc_cf_mllib(uservector.training_vector)\n",
    "predicted2 = prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=22502, product=12, rating=2.145246574980865),\n",
       " Rating(user=22514, product=12, rating=1.8239622809024438),\n",
       " Rating(user=22526, product=12, rating=1.6218700820020784),\n",
       " Rating(user=22538, product=12, rating=3.22630662094852),\n",
       " Rating(user=22550, product=12, rating=2.568704193724831)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(predicted2)\n",
    "predicted2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# both ways are the same thing as\n",
    "# predicted = algorithms.cf.calc_cf_mllib(uservector.training_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: you execute using the __make_prediction() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# TODO: will implement later\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hermes import *\n",
    "\n",
    "cargo.user_recommenders = [\"ALS\"]\n",
    "cargo.content_recommenders = []\n",
    "\n",
    "# call make_prediction function\n",
    "hermes.__make_prediction(cargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = cargo.vectors[0]\n",
    "prediction_vector = mv.prediction_vector\n",
    "print type(prediction_vector)\n",
    "prediction_vector.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: __calculate_metrics()\n",
    "**For those who use [MovieLens 1M CF test src code](http://l41-srv-mcdh32.b.internal:8880/notebooks/Hermes/MovieLens%201M%20CF%20test%20src%20code.ipynb#) as guidance, this is accomplishing cell # 11.**\n",
    "\n",
    "Function: \n",
    "* __calculate_metrics() tests the metrics specified by the user. \n",
    "* __calculate_metrics() implements the calculate_metrics_state of the state machine.\n",
    "\n",
    "```bash\n",
    "def __calculate_metrics(cargo):\n",
    "    \"\"\"calculate_metrics_state without the state machine.\"\"\"\n",
    "\n",
    "    if Globals.verbose: Globals.logger.debug(\"In calculate_metrics_state:\")\n",
    "\n",
    "    # create a metric executor\n",
    "    executor = mg.MetricExecutor(mg.Metric())\n",
    "\n",
    "    for i in range(0, len(cargo.vectors)):\n",
    "        Globals.logger.info(\"-\" * 80)\n",
    "        Globals.logger.info(\"Data: %s\" % cargo.vectors[i].data.datapath)\n",
    "        for m in cargo.metrics:\n",
    "            # check if metric exists\n",
    "            metric = mg.MetricFactory().create_obj_metric(m)\n",
    "            # set metric in executor\n",
    "            executor.change_metric(metric)\n",
    "            # execute the metric\n",
    "            with Timer() as t:\n",
    "                Globals.logger.info(\"Metric: %s = %f\" % (m, executor.execute(cargo.vectors[i])))\n",
    "            if Globals.verbose: Globals.logger.debug(\"Calculating metric takes %s seconds\" % t.secs)\n",
    "        Globals.logger.info(\"-\" * 80)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: You implement what is already in __calculate_metrics() manually yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import modules.metricgenerator \n",
    "\n",
    "# create metric executor\n",
    "executor = modules.metricgenerator.MetricExecutor(modules.metricgenerator.Metric())\n",
    "\n",
    "# create metric object\n",
    "metric_str = \"RMSE\"\n",
    "rmse_metric = modules.metricgenerator.MetricFactory().create_obj_metric(metric_str)\n",
    "\n",
    "# set metric in executor \n",
    "executor.change_metric(rmse_metric)\n",
    "\n",
    "# calculate metric\n",
    "rmse = executor.execute(uservector)\n",
    "\n",
    "print \"RMSE: \", rmse\n",
    "\n",
    "# switch metric object\n",
    "metric_str = \"MAE\"\n",
    "mae_metric = modules.metricgenerator.MetricFactory().create_obj_metric(metric_str)\n",
    "executor.change_metric(mae_metric)\n",
    "\n",
    "# calculate metric\n",
    "mae = executor.execute(uservector)\n",
    "\n",
    "print \"MAE: \", mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "import algorithms.performance_metrics\n",
    "\n",
    "# instead of doing the step above, you can also call the function directly\n",
    "rmse = algorithms.performance_metrics.calculate_rmse(uservector.test_vector, uservector.prediction_vector)\n",
    "print \"RMSE: \", rmse\n",
    "\n",
    "mae = algorithms.performance_metrics.calculate_mae(uservector.test_vector, uservector.prediction_vector)\n",
    "print \"MAE: \", mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# both ways are the same thing as\n",
    "# rmse = algorithms.performance_metrics.calculate_rmse(uservector.test_vector, uservector.prediction_vector)\n",
    "# mae = algorithms.performance_metrics.calculate_mae(uservector.test_vector, uservector.prediction_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: you execute using the __calculate_metrics() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hermes import *\n",
    "\n",
    "cargo.metrics = [\"ALS\"]\n",
    "\n",
    "# call calculate_metrics function\n",
    "hermes.__calculate_metrics(cargo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
